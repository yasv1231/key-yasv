#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç®€åŒ–çš„YOLOæ¼”ç¤ºè„šæœ¬
è§£å†³PyTorchå…¼å®¹æ€§é—®é¢˜
"""

import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import time

# è®¾ç½®ç¯å¢ƒå˜é‡è§£å†³PyTorchå…¼å®¹æ€§é—®é¢˜
os.environ['TORCH_LOAD_WEIGHTS_ONLY'] = 'False'

def load_yolo_model():
    """åŠ è½½YOLOæ¨¡å‹"""
    print("ğŸ“¥ åŠ è½½YOLOv8næ¨¡å‹...")
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    model_path = 'yolov8n.pt'
    if not os.path.exists(model_path):
        print("âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œ download_model_manual.py")
        return None
    
    file_size = os.path.getsize(model_path) / (1024 * 1024)
    print(f"âœ… æ‰¾åˆ°æ¨¡å‹æ–‡ä»¶: {model_path} ({file_size:.1f} MB)")
    
    try:
        from ultralytics import YOLO
        model = YOLO(model_path)
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼")
        return model
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return None

def create_test_image():
    """åˆ›å»ºæµ‹è¯•å›¾åƒ"""
    print("ğŸ¨ åˆ›å»ºæµ‹è¯•å›¾åƒ...")
    
    # åˆ›å»ºç™½è‰²èƒŒæ™¯
    img = np.ones((480, 640, 3), dtype=np.uint8) * 255
    
    # ç»˜åˆ¶å¤šä¸ªå½¢çŠ¶
    # çŸ©å½¢
    cv2.rectangle(img, (50, 200), (200, 350), (0, 0, 255), -1)
    cv2.rectangle(img, (60, 210), (190, 340), (255, 255, 255), -1)
    
    # åœ†å½¢
    cv2.circle(img, (400, 150), 60, (0, 255, 0), -1)
    cv2.circle(img, (400, 150), 40, (255, 255, 255), -1)
    
    # æ¤­åœ†
    cv2.ellipse(img, (500, 350), (100, 50), 0, 0, 360, (255, 0, 0), -1)
    cv2.ellipse(img, (500, 350), (80, 40), 0, 0, 360, (255, 255, 255), -1)
    
    # æ·»åŠ æ–‡å­—
    cv2.putText(img, 'YOLO Test Image', (150, 50), 
                cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 0, 0), 2)
    
    return img

def run_detection(model):
    """è¿è¡Œç›®æ ‡æ£€æµ‹"""
    print("ğŸ” å¼€å§‹ç›®æ ‡æ£€æµ‹...")
    
    # åˆ›å»ºæµ‹è¯•å›¾åƒ
    test_image = create_test_image()
    test_path = 'test_image.jpg'
    cv2.imwrite(test_path, test_image)
    print(f"ğŸ’¾ æµ‹è¯•å›¾åƒå·²ä¿å­˜: {test_path}")
    
    try:
        # è¿›è¡Œæ£€æµ‹
        start_time = time.time()
        results = model(test_path)
        detection_time = time.time() - start_time
        
        print(f"â±ï¸  æ£€æµ‹è€—æ—¶: {detection_time:.2f} ç§’")
        
        # åˆ†æç»“æœ
        for r in results:
            boxes = r.boxes
            if boxes is not None and len(boxes) > 0:
                print(f"ğŸ“Š æ£€æµ‹åˆ° {len(boxes)} ä¸ªç›®æ ‡:")
                for i, box in enumerate(boxes):
                    conf = box.conf[0].cpu().numpy()
                    cls = int(box.cls[0].cpu().numpy())
                    class_name = model.names[cls]
                    print(f"   {i+1}. {class_name} (ç½®ä¿¡åº¦: {conf:.3f})")
            else:
                print("ğŸ“Š æœªæ£€æµ‹åˆ°ç›®æ ‡")
        
        # ä¿å­˜ç»“æœ
        annotated = results[0].plot()
        result_path = 'detection_result.jpg'
        cv2.imwrite(result_path, annotated)
        print(f"ğŸ–¼ï¸  ç»“æœå›¾åƒå·²ä¿å­˜: {result_path}")
        
        # åˆ›å»ºå¯¹æ¯”å›¾
        plt.figure(figsize=(12, 6))
        plt.subplot(1, 2, 1)
        plt.imshow(cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB))
        plt.title('åŸå§‹å›¾åƒ')
        plt.axis('off')
        
        plt.subplot(1, 2, 2)
        plt.imshow(cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB))
        plt.title('æ£€æµ‹ç»“æœ')
        plt.axis('off')
        
        plt.tight_layout()
        plt.savefig('comparison.png', dpi=150, bbox_inches='tight')
        plt.close()
        print("ğŸ“ˆ å¯¹æ¯”å›¾å·²ä¿å­˜: comparison.png")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ£€æµ‹å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 50)
    print("ğŸ¯ YOLOç®€åŒ–æ¼”ç¤º")
    print("=" * 50)
    
    # åŠ è½½æ¨¡å‹
    model = load_yolo_model()
    if model is None:
        return False
    
    # æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
    print(f"\nğŸ“‹ æ¨¡å‹ä¿¡æ¯:")
    print(f"   æ”¯æŒç±»åˆ«æ•°: {len(model.names)}")
    print(f"   ä¸»è¦ç±»åˆ«: person, car, truck, bus, bicycle, motorcycle")
    
    # è¿è¡Œæ£€æµ‹
    success = run_detection(model)
    
    if success:
        print("\nğŸ‰ YOLOæ¼”ç¤ºå®Œæˆï¼")
        print("ğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
        files = ['test_image.jpg', 'detection_result.jpg', 'comparison.png']
        for file in files:
            if os.path.exists(file):
                size = os.path.getsize(file) / 1024
                print(f"   âœ… {file} ({size:.1f} KB)")
    else:
        print("\nâŒ æ¼”ç¤ºå¤±è´¥")
    
    return success

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\nğŸ‘‹ ç¨‹åºè¢«ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ ç¨‹åºå‡ºé”™: {e}")
